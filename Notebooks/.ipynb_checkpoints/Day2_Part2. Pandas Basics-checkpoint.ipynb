{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas 1. Fundamentos \n",
    "\n",
    "Esta libreta introduce al módulo [pandas](https://pandas.pydata.org), descrito en su sitio ofical como \n",
    "\n",
    "> a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
    "built on top of the Python programming language.\n",
    "\n",
    "Más precisamente, pandas introduce estructuras tabulares implementadas sobre el arreglo de la paquetería numpy. \n",
    "Puede consultarse el libro [_Python for Data Analysis_](https://www.cin.ufpe.br/~embat/Python%20for%20Data%20Analysis.pdf) para profundizar en distintos aspectos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas introduce la estructura tabular básica del análisis de datos.  La estructura tabular incluye cada una de las variables en una columna y cada observación en un renglón (tidy data).  Obsérvese que cada columna es de un tipo distinto, lo cual permite trabajar con estructuras de datos heterogéneas.  Técnicamente, esto se logra haciendo que cada columna sea un arreglo unidimensional de numpy etiquetado.  Estos arreglos etiquetados tienen el tipo \"pandas Series\", como veremos más adelante, y son la base del objeto DataFrame.\n",
    "\n",
    "Aunque es menos usual en la práctica del análsis de datos, puede formarse una base de datos a partir de un diccionario.  En ese caso las llaves (keys) funcionan como _nombres de variable_ y los valores (values) funcionan como observaciones (de cada variable).  \n",
    "\n",
    "Para empezar, debermos cargar el módulo pandas con un alias.  Generalmente lo haremos con:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "y trabajaremos con las funciones del módulo de la forma usual `pd.<nombre de función>(args)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pais</th>\n",
       "      <th>maneja_derecha</th>\n",
       "      <th>autos_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>True</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>False</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japón</td>\n",
       "      <td>False</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rusia</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marruecos</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Egipto</td>\n",
       "      <td>True</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pais  maneja_derecha  autos_per_capita\n",
       "0  Estados Unidos            True               809\n",
       "1       Australia           False               731\n",
       "2           Japón           False               588\n",
       "3           India           False                18\n",
       "4           Rusia            True               200\n",
       "5       Marruecos            True                70\n",
       "6          Egipto            True                45"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "paises = ['Estados Unidos', 'Australia', 'Japón', 'India', 'Rusia', 'Marruecos', 'Egipto']\n",
    "md =  [True, False, False, False, True, True, True]\n",
    "apc = [809, 731, 588, 18, 200, 70, 45]\n",
    "mi_dict = {\"pais\":paises, \"maneja_derecha\":md, \"autos_per_capita\":apc}\n",
    "\n",
    "autos = pd.DataFrame(mi_dict)\n",
    "autos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las etiquetas de renglón pueden cambiarse.  Por ejemplo, para usar el código abreviado de cada país, podríamos hacer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = ['US', 'AUS', 'JPN', 'IN', 'RU', 'MOR', 'EG']\n",
    "autos.index = row_labels\n",
    "autos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de objetos tipo lista, se debe tener una lista (de listas) que contenga una lista por cada columna.  Los nombres de columna deberán venir de otra lista y todo deberá agruparse en un diccionario.  El procedimiento es el siguiente:\n",
    "\n",
    "```python\n",
    "lista_pais = ['Estados Unidos', 'España', 'Italia']\n",
    "lista_casos = [337737, 135032, 129948]\n",
    "lista_datos = [lista_pais, lista_casos]\n",
    "lista_colnames = ['pais', 'num. casos']\n",
    "\n",
    "zipped = list(zip(lista_colnames, lista_datos))\n",
    "pd.DataFrame(dict(zipped))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_pais = ['Estados Unidos', 'España', 'Italia']\n",
    "lista_casos = [337737, 135032, 129948]\n",
    "lista_datos = [lista_pais, lista_casos]\n",
    "lista_colnames = ['pais', 'num. casos']\n",
    "\n",
    "zipped = list(zip(lista_colnames, lista_datos))\n",
    "zipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un poco más práctico\n",
    "\n",
    "### 1. Importación desde archivos .csv\n",
    "\n",
    "Mucho más comunmente, generaremos la base de datos importando una importación de algún archivo simple, como un csv.  Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>cont</th>\n",
       "      <th>life_exp</th>\n",
       "      <th>gdp_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2007</td>\n",
       "      <td>31889923.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>43.828</td>\n",
       "      <td>974.580338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2007</td>\n",
       "      <td>3600523.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>76.423</td>\n",
       "      <td>5937.029526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>2007</td>\n",
       "      <td>33333216.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>72.301</td>\n",
       "      <td>6223.367465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>Angola</td>\n",
       "      <td>2007</td>\n",
       "      <td>12420476.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>42.731</td>\n",
       "      <td>4797.231267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2007</td>\n",
       "      <td>40301927.0</td>\n",
       "      <td>Americas</td>\n",
       "      <td>75.320</td>\n",
       "      <td>12779.379640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1655</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2007</td>\n",
       "      <td>85262356.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>74.249</td>\n",
       "      <td>2441.576404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1667</td>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>2007</td>\n",
       "      <td>4018332.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>73.422</td>\n",
       "      <td>3025.349798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1679</td>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>2007</td>\n",
       "      <td>22211743.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>62.698</td>\n",
       "      <td>2280.769906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1691</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>2007</td>\n",
       "      <td>11746035.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>42.384</td>\n",
       "      <td>1271.211593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1703</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2007</td>\n",
       "      <td>12311143.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>43.487</td>\n",
       "      <td>469.709298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             country  year  population      cont  life_exp  \\\n",
       "0            11         Afghanistan  2007  31889923.0      Asia    43.828   \n",
       "1            23             Albania  2007   3600523.0    Europe    76.423   \n",
       "2            35             Algeria  2007  33333216.0    Africa    72.301   \n",
       "3            47              Angola  2007  12420476.0    Africa    42.731   \n",
       "4            59           Argentina  2007  40301927.0  Americas    75.320   \n",
       "..          ...                 ...   ...         ...       ...       ...   \n",
       "137        1655             Vietnam  2007  85262356.0      Asia    74.249   \n",
       "138        1667  West Bank and Gaza  2007   4018332.0      Asia    73.422   \n",
       "139        1679         Yemen, Rep.  2007  22211743.0      Asia    62.698   \n",
       "140        1691              Zambia  2007  11746035.0    Africa    42.384   \n",
       "141        1703            Zimbabwe  2007  12311143.0    Africa    43.487   \n",
       "\n",
       "          gdp_cap  \n",
       "0      974.580338  \n",
       "1     5937.029526  \n",
       "2     6223.367465  \n",
       "3     4797.231267  \n",
       "4    12779.379640  \n",
       "..            ...  \n",
       "137   2441.576404  \n",
       "138   3025.349798  \n",
       "139   2280.769906  \n",
       "140   1271.211593  \n",
       "141    469.709298  \n",
       "\n",
       "[142 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gapminder = pd.read_csv(\"../Datos/gapminder.csv\")\n",
    "gapminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la estructura del archivo csv es la siguiente:\n",
    "\n",
    "```python\n",
    "  ,country, year, population, cont, life_exp, gdp_cap\n",
    "11, Afghanistan, 2007, 31889923, Asia, 43.828, 974.580338\n",
    "23, Albania ...\n",
    "```\n",
    "\n",
    "La primera columna, que no tiene nombre, aparece en la importación con la etiqueta **Unnamed:0**; pero no es utilizada como etiqueta de renglones (la estructura del csv sugiere que esa es la intención del valor).  Para arreglar esto, podemos usar el argumento `index_col` en el que especificaremos que la columna de índice 0 se debe utilizar como etiqueta de renglón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gapminder = pd.read_csv(\"../Datos/gapminder.csv\", index_col = 0)\n",
    "gapminder = gapminder.filter(['cont'])\n",
    "dict = {'Africa': 'green',\n",
    " 'Americas': 'orange',\n",
    " 'Asia': 'blue',\n",
    " 'Europe': 'yellow',\n",
    " 'Oceania': 'red'}\n",
    "colors = gapminder.cont.map(dict)\n",
    "colors.to_csv('../Datos/Numpy_Colors.txt', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore `help(pd.read_csv)` y piense cuáles de los argumentos ahí presentes pueden serle útiles (y cómo) en el proceso de importación de sus datos.\n",
    "\n",
    "#### Y luego, qué tenemos ahí?\n",
    "\n",
    "Dos métodos comunes para inspeccionar la base de datos son `.head()` y `.tail()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creada la base de datos, podemos acceder a la información de diversas maneras, como:\n",
    "* selector posicional con [ ]\n",
    "* `loc` e `iloc`\n",
    "\n",
    "Con [ ] podemos seleccionar variables enteras o hacer _slicing_.  Por ejemplo, podemos seleccionar la variable `cont`con el comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder['cont']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese que este objeto no en un arreglo común.  Qué tipo es? Investíguelo.\n",
    "\n",
    "Este tipo es la base del objeto DataFrame en pandas.  Se puede describir como un arreglo etiquetado.  De hecho, utilizando el _atributo_ `values` puede conseguir sus valores.\n",
    "\n",
    "Sería más intuitivo pensar en este objeto como una base de datos unidimensional; pero esto conllevaría tener el tipo DataFrame, que el objeto no tiene.  Para que la respuesta sea del tipo DataFrame, se puede utilizar el selector [ [ ...  ] ].  \n",
    "\n",
    "Intente las tres acciones en la celda siguiente (y verifique que el selector [ [ ... ] ] regresa un objeto de tipo DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso del selector [ [ ... ] ]  es generalizable como sigue:  Insertamos una _lista_ en el selector original [  ].  Por ejemplo, si queremos seleccionar las columnas `'country' y 'cont'` podemos usar el comando\n",
    "```python\n",
    "gapminder[['country', 'cont']]\n",
    "```\n",
    "En este caso la lista `['country', 'cont']` funciona como seleccionador y el tipo de la respuesta sería (pandas.core.frame.)DataFrame. \n",
    "\n",
    "Realice la selección de las columnas _country, year, y gdp_cap_ de la base de datos `gapminder` y corrobore que el tipo de la selección resultante es DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos utilizar el selector [  ]  con argumento rango numérico para seleccionar renglones:\n",
    "```python\n",
    "gapminder[1:4]\n",
    "```\n",
    "Ten en cuenta que el índice de la derecha no es incluído en la selección. Prueba esta forma de seleccionar para hallar las observaciones 16 a 19 de la base `gapminder`.  Ten en cuenta que los números que se obtienen a la extrema izquierda son los **nombres de observación**, no su número en la base!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acceder de forma más precisa a la información contenida en una base de datos del tipo DataFrame, se tienen las funciones \n",
    "\n",
    "* `loc` : basado en etiquetas\n",
    "* `iloc`: basado en posiciones (enteras) \n",
    "\n",
    "Compare el resultado de `autos.loc['US']` con `autos.loc[['US']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini quiz\n",
    "Seleccione los renglones 'US', 'JPN', y 'RU' de la base de datos `autos` en formato DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadiendo los nombres de columna como segundo argumento en forma de una lista es posible seleccionar en ambas direcciones.  Por ejemplo, \n",
    "```python\n",
    "gapminder.loc[[11, 59, 1655], [\"country\", \"gdp_cap\"]]\n",
    "```\n",
    "\n",
    "Seleccione las variables `pais` y `autos_per_capita`para las observaciones etiquetadas como 'US', 'JPN', y 'RU' en la base de datos `autos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El uso del slice vacío, `:` permite seleccionar todos los elementos en cualquier dirección. Por ejemplo\n",
    "```python\n",
    "gapminder[[11, 59], :]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, se puede utilizar `iloc` y seleccionar con base en el índice de posición, entero. Por ejemplo\n",
    "```python\n",
    "autos.iloc[1]\n",
    "autos.iloc[[1]]\n",
    "autos.iloc[1:3, 0:2]\n",
    "```\n",
    "Selecciona las primeras 30 observaciones de las variables `country`, `year`, y `population` de la base de datos `gapminder` utilizando `gapminder.iloc`.  Después, selecciona todas las variables para esas mismas observaciones con el mismo método.  Finalmente, imprime el producto interno bruto per cápita de Albania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante tener muy claro el tipo del objeto respuesta...Prevea, y después verifique, el tipo de respuesta de los siguientes dos comandos\n",
    "```python\n",
    "gapminder.iloc[:, 1]\n",
    "gapminder.iloc[:, [1]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tu turno.\n",
    "1. Cargue, en un objeto DataFrame nombrado `wb`, los contenidos del archivo `world_ind_pop_data.csv`\n",
    "2. Repare la etiqueta de los renglones, de ser necesario\n",
    "3. Examine sus datos usando los métodos `head`y `tail`\n",
    "4. Utilice el método `.info()` para determinar cuántas observaciones nulas hay en los datos\n",
    "5. Vuelva a caragar el archivo `world_ind_pop_data.csv` pero esta vez utilice como etiqueta de observación la variable `CountryCode`\n",
    "6. Cambie los nombres de su base de datos por su versión traducida al español asignando el atributo `.columns` a su nuevo valor.  \n",
    "7. Aplique el método `.describe()` a su base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No siempre es tan sencillo...\n",
    "\n",
    "La página web de [SISLO](http://www.sidc.be/silso/datafiles) contiene la base de datos del número de manchas solares (sunspot) diarias y la podemos importar directamente desde su url con: \n",
    "\n",
    "```python\n",
    "url = 'http://www.sidc.be/silso/INFO/sndtotcsv.php'\n",
    "data = pd.read_csv(url)\n",
    "```\n",
    "Realice esta importación y juzgue qué problemas tiene esta importación. ¿Cómo lo arreglamos?  Visitemos [la página de información del juego de datos](http://www.sidc.be/silso/infosndtot).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requerimos:**\n",
    "1. Definir apropiadamente el separador\n",
    "2. Evitar que `pandas` asigne un nombre automático de columna\n",
    "3. Poner nombres de columna apropiados\n",
    "4. Distinguir las observaciones que son NA de las que son un dato en la columna 5 (4 en Python)\n",
    "5. Poner las fechas en un formato conveniente para cálculos en Python\n",
    "6. Utilizar las fechas como índice (nombre de renglón) \n",
    "\n",
    "Obsérvese el problema que nos provoca no utilizar el argumento `skipinitialspace`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este [link](https://strftime.org) contiene referencias para importar y sintetizar fechas en formatos que no sean el estándar.\n",
    "\n",
    "### Excepciones: Archivos corruptos\n",
    "Los parámetros `error_bad_lines` y `warn_bad_lines` del comando `read_csv` nos pueden ayudar a leer datos de un archivo `.csv` corrupto.  En particular, cuando algún renglón tiene más registros que variables en la base, Pandas levanta una excepción `pd.io.common.ParserError`.  Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    datos = pd.read_csv('../Datos/gapminder_corrupt.csv')\n",
    "    datos.head(15)\n",
    "except pd.io.common.ParserError:\n",
    "    print('Este archivo contiene datos corruptos!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice primero el parámetro `error_bad_lines` para arreglar este problema. ¿Cuántas líneas causaban este problema, y cuáles? \n",
    "Utilice el parámetro `warn_bad_lines` para realizar la importación sin mensajes de advertencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('../Datos/gapminder_corrupt.csv',\n",
    "                    error_bad_lines = False,\n",
    "                    warn_bad_lines = True)\n",
    "datos.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importación desde bases de datos SQL\n",
    "\n",
    "Para ejemplificar la importación de una base de datos, utilizaremos los datos de la liga Europea de football, disponible [aquí](https://www.kaggle.com/hugomathien/soccer), que contiene información sobre más de 25,000 juegos y 10,000 jugadores.  El formato de este archivo es `.sqlite`y para importarlo debemos primero conectar con la base de datos como sigue:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "data_engine = create_engine('sqlite:///../Datos/database.sqlite')\n",
    "inspector = inspect(data_engine)\n",
    "print(data_engine.table_names())\n",
    "print(inspector.get_columns('League'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese el uso del prefijo `sqlite:///` para introducir la direción de los datos. El listado anterior muestra tablas y podemos leerlas con el método `read_sql`.  La primera forma: sin uso de SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = pd.read_sql('Country', data_engine)\n",
    "country.head(5)\n",
    "# Esta tabla es un pd.DataFrame como cualquier otro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer este mismo proceso usando SQL. Para ello debemos generar primero la consulta (query) y después usarla en vez del nombre de tabla. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = \"\"\"\n",
    "SELECT *\n",
    "FROM Country;\n",
    "\"\"\"\n",
    "country = pd.read_sql(my_query, data_engine)\n",
    "country.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_goals_per_season = \"\"\"\n",
    "SELECT season, \n",
    "       max(home_team_goal + away_team_goal) AS max_goals_season,\n",
    "       (SELECT MAX(home_team_goal + away_team_goal) FROM match) AS overall_max_goals\n",
    "FROM match\n",
    "GROUP BY season\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(max_goals_per_season, data_engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Importación de archivos JSON\n",
    "\n",
    "El formato [JSON](https://www.json.org/json-en.html) (JavaScript Object Notation) es muy popular actualmente pues permite la transmisión de muchos tipos de información en un formato de fácil interpretación y, de hecho, muy similar al diccionario de Python!  Cada objeto en un archivo JSON se organiza como parejas del tipo `name:value` y es contenido entre llaves.  El comando para leerlo es, sí, `pd.read_json`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_report = pd.read_json('../Datos/NYC Department of Homeless Services.json',\n",
    "                         orient = 'record')\n",
    "nyc_report.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y las APIs apá?\n",
    "\n",
    "Todo muy bien; pero... Generalmente los archivos `.json` vendrán de conectar con las APIs de distintos sitios.  Para quien no esté familiarizado con las APIs, aquí algunos recursos:\n",
    "\n",
    "*  [What is an API](https://www.callr.com/blog/what-is-an-api/)\n",
    "*  [An introduction to APIs](https://zapier.com/learn/apis/)\n",
    "\n",
    "Aunque Python incluye varios paquetes dedicados a APIs específicas, usaremos primero un paquete [Requests](https://requests.readthedocs.io/es/latest/) que es una librería genérica para HTTP. Para utilizarla, necesitamos hacer una **solicitud** con\n",
    "\n",
    "```python\n",
    "import requests\n",
    "url = 'https://alguna_direccion_red.dominio'\n",
    "response = requests.get(url)\n",
    "```\n",
    "\n",
    "Cada API tiene su propio método de consulta, sus propias especificaciones. En general tenemos tres elementos básicos:\n",
    "\n",
    "  1. La url de la API \n",
    "  2. Los parámetros de la búsqueda de información en el sitio\n",
    "  3. Las cabeceras del protocolo HTTP (usualmente los datos de identificación del cliente)\n",
    "  \n",
    "El objeto devuelto por `.get()` será un archivo JSON que podremos leer con el método `.json()` del objeto `response`.  Los parámetros adicionales (particulares de cada API) se insertan en el argumento `params` y como un diccionario en la forma: \n",
    "```python\n",
    "params = {'nombre1':'valor1', 'nombre2':'valor2'}\n",
    "```\n",
    "\n",
    "#### Ejemplo 1. La API de NewsApi: una API de fácil acceso\n",
    "\n",
    "La página newsapi.org nos permite obtener encabezados de noticias y blogs.  Después de registrarnos, veremos en [su página](https://newsapi.org/docs/get-started) la forma de realizar una consulta.  Aprendemos que:\n",
    "\n",
    "  1. Debemos pasar nuestra llave en el encabezado HTTP `X-Api-Key`\n",
    "  2. La API tiene tres endpoints, a saber: `/v2/top-headlines`para los titulares de mayor impacto, `v2/everything` para...todo, y `v2/sources` donde podemos consultar las fuentes de informacion indizadas en newsapi.org\n",
    "  3. Cada endpoint tiene sus propios parámetros.  \n",
    "  \n",
    "Para consultar las últimas noticias de México, usariamos el parámetro `country = mx`.  Consultemos las últimas noticias en nuestro país (de todas las fuentes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta respuesta es la traducción de un archivo JSON a un diccionario de Python.  Ejecutando\n",
    "```python\n",
    "response_dict.keys()\n",
    "```\n",
    "observamos que las llaves son: `status` , `totalResults`, y `articles`.  Centrando nuestro interés en las noticias en sí, podemos generar una base de datos como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(response_dict['articles'])\n",
    "response_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tu Turno\n",
    "\n",
    "Usando el API de NewsApi, consulta los titulares principales para México en materia de ciencia con palabra clave CONACYT y convierte tu respuesta primero en un diccionario y luego en una base de datos de `pandas`.  Puedes incluir la palabra clave \"tecnología\" a tu búsqueda?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 3: Yelp Business Search Engine API\n",
    "\n",
    "En este ejemplo veremos cómo lidiar con JSONs anidados.  Para ello, haremos una solicitud a la API de Yelp. Comience [aquí](https://www.yelp.com/fusion) para conseguir su token individual y replicar este ejemplo.  En él buscamos librerías en Ciudad de México."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "api_url = 'https://api.yelp.com/v3/businesses/search'\n",
    "params = {'term':'hotel', 'location':'New York'}\n",
    "headers = {'Authorization':'Bearer [...poner el token aquí...]'}\n",
    "response = requests.get(api_url, params = params, headers = headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe la estructura _anidada_ de este JSON.  En particular, ponga atención a la doble respuesta en las columnas `coordinates` y `categories` organizadas ambas como un diccionario.  Ejecute el siguiente comando y navegue para ver estas columnas.\n",
    "\n",
    "```python\n",
    "pd.DataFrame(response.json()['businesses']).head(3)\n",
    "```\n",
    "\n",
    "En estos casos se puede utilizar el método `.json_normalize()` de `pandas`.  Esto _aplanará_ el resultado generando columnas nombradas bajo la convención `atributo.atributoanidado` pero el separador se puede cambiar con el argumento `sep`.  Ejecute\n",
    "\n",
    "```python\n",
    "response_json = response.json()\n",
    "pd.json_normalize(response_json['businesses'])\n",
    "```\n",
    "\n",
    "Puede seleccionar qué atributo normalizar y qué información extraer. Por ejemplo, intente\n",
    "\n",
    "```python\n",
    "response_df =  pd.json_normalize(response_json['businesses'],\n",
    "                  sep = '_',\n",
    "                  record_path = 'categories',\n",
    "                  meta = ['name', 'alias', 'rating',\n",
    "                         ['location', 'address1'],\n",
    "                         'display_phone'],\n",
    "                  meta_prefix = 'hotel_')\n",
    "respose_df.head(5)\n",
    "```\n",
    "\n",
    "¿Cuántos resultados tenemos?  Escribamos `response_json.shape()`.  En mi caso, veo 25 resultados (en 7 columnas); pero ¿Son todos?  La documentación de la API nos muestra que por defecto obtendremos 20 resultados...podemos ejecutar\n",
    "\n",
    "```python\n",
    "response_df['hotel_name'].nunique()\n",
    "## otra forma sería: \n",
    "## response_df.hotel_name.nunique()\n",
    "```\n",
    "\n",
    "Estas limitaciones son típicas en las APIs, para ahorrar ancho de banda.  No obstante, tenemos un parámetro extra, `offset` (vea la documentación) y podemos usarlo para descargar más datos.\n",
    "\n",
    "```python\n",
    "params['offset'] = 20\n",
    "sig_response = response = requests.get(api_url, \n",
    "                                       params = params, \n",
    "                                       headers = headers)\n",
    "sig_response_df = pd.json_normalize(sig_response.json()['business'],\n",
    "                                    sep = '_',\n",
    "                                    record_path = 'categories',\n",
    "                                     meta = ['name', 'alias', 'rating',\n",
    "                                            ['location', 'address1'],\n",
    "                                             'display_phone'],\n",
    "                                     meta_prefix = 'hotel_')\n",
    "sig_response_df.head(5)\n",
    "```\n",
    "\n",
    "Teniendo esto, podemos juntarlos en una sola base:\n",
    "\n",
    "```python\n",
    "response_df.append(sig_response_df, ignore_index = True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = response.json()\n",
    "response_df =   pd.json_normalize(response_json['businesses'],\n",
    "                  sep = '_',\n",
    "                  record_path = 'categories',\n",
    "                  meta = ['name', 'alias', 'rating',\n",
    "                         ['location', 'address1'],\n",
    "                         'display_phone'],\n",
    "                  meta_prefix = 'hotel_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_df.shape)\n",
    "\n",
    "print(response_df['hotel_name'].nunique())\n",
    "response_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['offset'] = 20\n",
    "sig_response = response = requests.get(api_url, \n",
    "                                       params = params, \n",
    "                                       headers = headers)\n",
    "sig_response_df = pd.json_normalize(sig_response.json()['businesses'],\n",
    "                                    sep = '_',\n",
    "                                    record_path = 'categories',\n",
    "                                     meta = ['name', 'alias', 'rating',\n",
    "                                            ['location', 'address1'],\n",
    "                                             'display_phone'],\n",
    "                                     meta_prefix = 'hotel_')\n",
    "sig_response_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_response = response_df.append(sig_response_df, ignore_index= True)\n",
    "print('Dimensiones actuales:', full_response.shape)\n",
    "print('Tenemos información sobre', full_response.hotel_name.nunique(), 'negocios.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tu turno: La API del DENUE; un poco más de trabajo\n",
    "\n",
    "Vea [la documentación de la API del DENUE](https://www.inegi.org.mx/servicios/api_denue.html#metBus), INEGI y escriba el código de una clase para comunicar con esta API.  La clase debe contener los métodos `buscar`, `ficha`, `nombre`, etc.  Incluya los atributos necesarios y los métodos que faciliten su manejo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiplomadoEnv",
   "language": "python",
   "name": "diplomadoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
