{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajando con datos en pandas\n",
    "\n",
    "Ya habiendo importado nuestros datos a pandas, nuestras siguientes tareas serán: limpieza de la base de datos, transformación de variables y cálculo de nuevos indicadores, consultas específicas (por agrupación, selección, filtrado, y reordenamiento), generación de reportes (en la forma de tablas o gráficos).  Antes que todo, podemos obtener un resumen de nuestra información con los métodos `.describe()` y `.info()`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "sueño = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/msleep.csv',\n",
    "                      index_col = 0)\n",
    "sueño.describe()\n",
    "```\n",
    "\n",
    "\n",
    "## 1. Fundamentos de limpieza de datos en pandas\n",
    "\n",
    "### Datos faltantes (NA)\n",
    "\n",
    "Lo primero que necesitamos en este rubro es reconocer los datos faltantes.  Pandas reconoce como faltantes los objetos de tipo `np.nan`(usado para variables numéricas) y el tipo nativo de Python `None`.  Usemos, como ejemplo, la serie\n",
    "\n",
    "```python \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ingredientes = pd.Series(['ajo', 'cebolla', 'pimiento', np.nan, 'sal', 'pimienta', None])\n",
    "```\n",
    "\n",
    "En pandas contamos con cuatro métodos básicos para lidiar con los datos ausentes\n",
    "\n",
    "Método|Desripción\n",
    "---|---\n",
    "isna(a.k.a isnull)|Vector lógico indicando los elementos ausentes como `True`\n",
    "notna (a.k.a notnull)| Negación lógica de `isnull`\n",
    "dropna| Filtra la base por la presencia de valores ausentes. Se puede modular el umbral de tolerancia.\n",
    "fillna| Imputación de valores en las observaciones ausentes. Puede ser un valor específico o un método de interpolación\n",
    "\n",
    "```python\n",
    "print(ingredientes.isna())\n",
    "print(ingredientes.notna())\n",
    "print(ingredientes.dropna())\n",
    "print(ingredientes.fillna('Sabe qué cosa'))\n",
    "```\n",
    "\n",
    "En una base, es decir, cuando tenemos más de una columna, hay más posibilidades:\n",
    "\n",
    "```python\n",
    "from numpy import nan as NA\n",
    "datos = pd.DataFrame([[1, 2, 3], [4, NA, NA], [NA, 5, 6], [NA, NA, NA]])\n",
    "print(datos, '\\n\\n')\n",
    "print(datos.dropna(), '\\n\\n') # elimina todos los renglones que contienen al menos un NaN\n",
    "print(datos.dropna(axis = 1),'\\n\\n') # elimina todas las columnas que contienen al menos un NaN\n",
    "print(datos.dropna(how = 'all'), '\\n\\n') # elimina un renglón si todas sus entradas son NaN\n",
    "print(datos.dropna(thresh = 2), '\\n\\n') # conserva los renglones con al menos 2 valores observado\n",
    "print(datos.dropna(subset = [0, 1]))\n",
    "```\n",
    "\n",
    "### Tu turno\n",
    "\n",
    "Usa los datos de `sueño` para responder estas preguntas:\n",
    "1. Cuántas horas sueña (`sleep_rem`) un mamífero en promedio? Cuál es la mediana? Cuál es el máximo?\n",
    "2. Cuántos datos faltantes hay en la variable `sleep_rem`? Qué porcentaje de las entradas de sueño total (`sleep_total`) son datos faltantes? Qué porcentaje de las observaciones sobre la forma de alimentación (`vore`) son genuinas?\n",
    "3. Cuál es el total de observaciones faltantes en el juego de datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  2.0  3.0\n",
      "1  4.0  NaN  NaN\n",
      "2  NaN  5.0  6.0\n",
      "3  NaN  NaN  NaN \n",
      "\n",
      "\n",
      "     0    1    2\n",
      "0  1.0  2.0  3.0 \n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3] \n",
      "\n",
      "\n",
      "     0    1    2\n",
      "0  1.0  2.0  3.0\n",
      "1  4.0  NaN  NaN\n",
      "2  NaN  5.0  6.0 \n",
      "\n",
      "\n",
      "     0    1    2\n",
      "0  1.0  2.0  3.0\n",
      "2  NaN  5.0  6.0 \n",
      "\n",
      "\n",
      "     0    1    2\n",
      "0  1.0  2.0  3.0\n"
     ]
    }
   ],
   "source": [
    "print(datos, '\\n\\n')\n",
    "print(datos.dropna(), '\\n\\n') # elimina todos los renglones que contienen al menos un NaN\n",
    "print(datos.dropna(axis = 1),'\\n\\n') # elimina todas las columnas que contienen al menos un NaN\n",
    "print(datos.dropna(how = 'all'), '\\n\\n') # elimina un renglón si todas sus entradas son NaN\n",
    "print(datos.dropna(thresh = 2), '\\n\\n') # conserva los renglones con al menos 2 valores observado\n",
    "print(datos.dropna(subset = [0, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción (no necesariamente muy recomendable) es imputar los valores ausentes con el método `.fillna()` que aceepta\n",
    "\n",
    "Argumento | Acción\n",
    "---|---\n",
    "valor | Imputar ese valor\n",
    "dict / Series / DataFrame | Indicando el valor de reemplazo para cada índice (al aplicarse sobre Series) o columna (al aplicarse sobre DataFrame)\n",
    "method | Puede ser `backfill` alias `bfill` o `pad` alias `ffill`.  Utilizan las observaciones pasadas o futuras para propagarlas en los valores ausentes\n",
    "axis | Determina sobre qué eje propagar o reemplazar\n",
    "limit| Limita la propagación de `bfill` o `ffill` a `limit` observaciones (de tipo `int`)\n",
    "\n",
    "```python\n",
    "print(datos, '\\n\\n')\n",
    "print(datos.fillna('Reemplazo'), '\\n\\n')\n",
    "print(datos.fillna({0:'Cero', 1:'Uno', 2:'Dos'}),'\\n\\n')\n",
    "print(datos.fillna(method = 'ffill'), '\\n\\n')\n",
    "print(datos.fillna(method = 'ffill', axis = 1), '\\n\\n')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de variable\n",
    "\n",
    "Los tipos de variable que usaremos en nuestros análisis de datos y la información que representan puede leers en la siguiente tabla:\n",
    "\n",
    "Contenido | Tipo de variable\n",
    "--- | ---\n",
    "Conteos, número de unidades, etc. | `int`\n",
    "Mediciones continuas (salario, temperatura, etc.) | `float`\n",
    "Clasificación binaria (sexo, afiliación partidaria, etc.) | `bool`\n",
    "Fechas | `datetime`\n",
    "Texto | `str`\n",
    "Categorías (clasificación) | `category`\n",
    "\n",
    "Una práctica usual es codificar factores como números enteros y dar un diccionario.  En estos casos merece la pena cambiar el tipo de registro de `int` a `category` para obtener información más relevante.  Por ejemplo, miremos la columna `color` de esta base de datos\n",
    "\n",
    "```python\n",
    "diamantes = pd.read_csv('../Datos/diamonds_factors.csv', parse_dates = [10])\n",
    "diamantes\n",
    "```\n",
    "El color está codificado con los números 1, 2, 3, ..., 7 y debería ser una variable categórica; pero en nuestra importación es una variable entera.  El resumen `diamantes['color'].describe()` es inútil.  Para arreglarlo simplemente cambiaremos el tipo como sigue:\n",
    "\n",
    "```python\n",
    "diamantes['color'] = diamantes['color'].astype('category')\n",
    "assert diamantes['color'].dtype == 'category'\n",
    "```\n",
    "Otro error común de clasificación de tipo ocurre cuando una columna numérica es registrada con sus unidades como en tiempo = _12 minutos_ o precio = $ 450.31.\n",
    "\n",
    "En estos casos el método `.str.strip('qué_quitar')` puede ser de utilidad.  \n",
    "\n",
    "### Tu turno\n",
    "Intenta corregir la columna `precio` de la base de datos de diamantes.  Para ello:\n",
    "0. Intenta una descripción de la columna de precios. Es la información relevante?\n",
    "1. Elimina el signo '$' usando el método `str.split('$')`\n",
    "2. Convierte la columna así obtenida en tipo `float`\n",
    "3. Escribe un assert statement para verificar este cambio de tipo\n",
    "4. Vuelve a hacer la descripción.  Los cambios merecen la pena?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de límites \n",
    "\n",
    "Cierto tipo de datos puede tener límites naturales; por ejemplo, una clasificación podría referir a cinco tipos distintos y con ello su rango estaría limitado a cinco valores.  No obstante, por múltiples razones podría haber registros que no cumplen con estos requisitos. \n",
    "\n",
    "En nuestro ejemplo, el campo de fecha de venta tiene un límite natural: la fecha actual.  Para corroborar que todas las fechas de venta han sido correctamente registradas, podemos ejecutar:\n",
    "\n",
    "```python\n",
    "import datetime as dt\n",
    "any(diamantes['date_sold'] > dt.datetime.today())\n",
    "```\n",
    "La respuesta `True` nos indica que existen registros fuera de fecha...\n",
    "\n",
    "### Tu turno\n",
    "1. Modificando el código anterior, determina cuántos registros están fuera de fecha\n",
    "2. Imprime solo esos renglones de la base de datos\n",
    "3. Opciones:\n",
    "\n",
    "    3.1 Cambia la observación de la columna `date_sold` a NA (`np.nan`) para estas observaciones e imprime de nuevo estos registros\n",
    "    3.2 En vez de cambiar los registros por NA, redefine la base de forma que incluya solo las observaciones correctamente registradas (Usa el método de selección `diamantes[...]`.\n",
    "    3.3 Repite el inciso anterior; pero ahora usando el método `.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registros duplicados \n",
    "\n",
    "Otro problema común en una base de datos es la de registros duplicados.  Para revisar si nuestra base de datos tiene registros duplicados podemos ejecutar.\n",
    "\n",
    "```python\n",
    "any(diamantes.duplicated())\n",
    "```\n",
    "\n",
    "El vector `diamantes.duplicated()` marca, por defecto, todas menos la primera ocurrencia de la repetición.  En nuestro caso las observaciones 15345, 39878, 41398, 50808, marcadas por el método, corresponden a ocurrencias de registros repetido.  Para ver todas las repeticiones, podemos usar el parámetro `keep = False`.  La otra opción posible es `subset` para elegir las columnas en las que se buscarán los repetidos (id, combinaciones únicas, etc.).\n",
    "\n",
    "### Tu turno\n",
    "\n",
    "1. Imprime todas los valores repetidos de la tabla con el método `.duplicated()`.  Asegúrate de ver todas las ocurrencias de cada caso (debe haber dos de cada registro).\n",
    "\n",
    "2. Ahora ordena tus resultados para mejor visualización con el método `sort_values(by = 'date_sold')\n",
    "\n",
    "3. Finalmente, utiliza el método `drop_duplicates()` de forma que la base creada conserve únicamente la **última** ocurrencia de cada registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más adelante, conforme desarrollemos más técnicas en Pandas, podremos abordar la solución de problemas más complejos con los datos como inconsistencias en las categorías de registro (tipo de sangre C+), registros múltiples para una misma categoría (como 'Mx', 'mx', 'MX', ' Mx', '      MX   '), exceso de categorías en una clasificación y la necesidad de reasignar grupos, formatos inapropiados en un campo de texto (email: nelson?muriel@gmailcom; teléfono: 4321) y más.\n",
    "\n",
    "### Preparación: diamantes_clean\n",
    "\n",
    "Utiliza la siguiente celda para recopilar todos los cambios que hicimos a la base `diamantes` y guarda el resultado final en el objeto `diamantes_clean`.   Tu base final debe tener dimensiones `53940 rows x 11 columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>date_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.68</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>3</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15309.0</td>\n",
       "      <td>7.63</td>\n",
       "      <td>7.70</td>\n",
       "      <td>4.68</td>\n",
       "      <td>2009-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.38</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>6</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2007-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Fair</td>\n",
       "      <td>4</td>\n",
       "      <td>I1</td>\n",
       "      <td>64.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>6.77</td>\n",
       "      <td>6.61</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2003-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32</td>\n",
       "      <td>Premium</td>\n",
       "      <td>2</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.37</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2007-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>5.07</td>\n",
       "      <td>5.11</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2003-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.54</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>6</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.27</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2011-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53940</th>\n",
       "      <td>0.38</td>\n",
       "      <td>Premium</td>\n",
       "      <td>3</td>\n",
       "      <td>VS2</td>\n",
       "      <td>60.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2016-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53941</th>\n",
       "      <td>1.07</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>6</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5373.0</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.62</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2011-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53942</th>\n",
       "      <td>1.21</td>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.8</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5597.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.64</td>\n",
       "      <td>4.27</td>\n",
       "      <td>2006-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53943</th>\n",
       "      <td>0.34</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.47</td>\n",
       "      <td>2.82</td>\n",
       "      <td>2007-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table    price     x     y  \\\n",
       "0       1.68  Very Good     3     VS2   61.1   60.0  15309.0  7.63  7.70   \n",
       "1       0.38      Ideal     6     SI1   61.8   54.0    593.0  4.66  4.70   \n",
       "2       1.20       Fair     4      I1   64.4   55.0   2655.0  6.77  6.61   \n",
       "3       0.32    Premium     2     SI1   62.3   58.0    720.0  4.40  4.37   \n",
       "4       0.50  Very Good     1     VS2   61.1   58.0   1646.0  5.07  5.11   \n",
       "...      ...        ...   ...     ...    ...    ...      ...   ...   ...   \n",
       "53939   0.54      Ideal     6     SI1   61.4   56.0   1114.0  5.25  5.27   \n",
       "53940   0.38    Premium     3     VS2   60.9   56.0   1026.0  4.72  4.67   \n",
       "53941   1.07      Ideal     6     VS1   62.0   53.0   5373.0  6.61  6.62   \n",
       "53942   1.21       Good     4     SI1   63.8   58.0   5597.0  6.75  6.64   \n",
       "53943   0.34       Good     2     SI1   63.3   57.0    556.0  4.44  4.47   \n",
       "\n",
       "          z  date_sold  \n",
       "0      4.68 2009-03-30  \n",
       "1      2.89 2007-05-10  \n",
       "2      4.31 2003-01-12  \n",
       "3      2.73 2007-05-31  \n",
       "4      3.11 2003-08-18  \n",
       "...     ...        ...  \n",
       "53939  3.23 2011-07-10  \n",
       "53940  2.86 2016-05-23  \n",
       "53941  4.10 2011-12-04  \n",
       "53942  4.27 2006-10-03  \n",
       "53943  2.82 2007-01-08  \n",
       "\n",
       "[53940 rows x 11 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamantes = pd.read_csv('../Datos/diamonds_factors.csv', parse_dates = [10])\n",
    "diamantes['color'] = diamantes['color'].astype('category')\n",
    "diamantes['price'] = diamantes['price'].str.strip('$').astype('float')\n",
    "bad_records = diamantes['date_sold'] > dt.datetime.today()\n",
    "index = diamantes[bad_records].index\n",
    "diamantes.drop(index = index)\n",
    "diamantes_clean = diamantes.drop_duplicates(keep = 'last')\n",
    "diamantes_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Los métodos de interacción con una tabla.\n",
    "\n",
    "Hay seis acciones básicas que nos serán de utilidad en el análisis de una tabla:\n",
    "1. Hacer consultas (`.query()`) sobre las columnas de una base de datos, p.ej. \"Restrignirse a los diamantes con una claridad \"VS2\" y color 3)\"\n",
    "2. Hacer un filtrado de columnas (`.filter()`) para utilizar únicamente las columnas que sean de nuestro interés, p. ej. mirar únicamente el quilataje, color, claridad, y precio de los diamantes.\n",
    "3. Generar nuevas columnas (`.assign()`) usando la información presente en la base de datos, p.ej. calcular el precio por quilate dividiendo `price` entre `carat`.\n",
    "4. Agrupar nuestra información en grupos para el análisis (`.groupby()`), p.ej. agrupar por `cut` para examinar el valor en cada categoría.\n",
    "5. Realizar cálculos agregados (`.agg()`) como medias, desviaciones estándar, etc., p.ej. calcular el precio medio de los diamantes de cada tipo de corte.\n",
    "6. Ordenar los resultados según una columna (`.sort_values()`).\n",
    "\n",
    "El código para las consultas especificadas en los ejemplos es el siguiente:\n",
    "\n",
    "```python\n",
    "diamantes_clean.query('clarity == \"VS2\" and color == 3')\n",
    "diamantes_clean.filter(['carat', 'color', 'clarity', 'price'])\n",
    "diamantes_clean.assign(ppcarat = lambda x: x.price/x.carat)\n",
    "diamantes_clean.groupby('cut') #en realidad no cambia nada, solo agrupa\n",
    "diamantes_clean.groupby('cut').agg(mean)\n",
    "```\n",
    "Obsérvese que en las últimas línea se concatenaron dos métodos. Como consejo de estilo, puede ser más legible el escribir esta consulta en la forma: \n",
    "\n",
    "```python\n",
    "(diamantes_clean\n",
    "  .groupby('cut')\n",
    "  .agg('mean'))\n",
    "```\n",
    "\n",
    "Ahora bien, podríamos concatenar un tercero si quisieramos exacta y únicamente los precios medios...\n",
    "\n",
    "Algunas funciones que podemos usar dentro de `.agg()` son:\n",
    "\n",
    "Función | Descripción\n",
    "---|---\n",
    "mean | Calcula la media (promedio aritmético)\n",
    "median | Calcula la mediana (percentil 50%)\n",
    "var | Calcula la varianza muestral\n",
    "std | Calcula la desviación estándar\n",
    "sum | Suma los elementos\n",
    "quantile | Calcula los cuantiles (percentiles) de la variable\n",
    "min | Calcula el valor mínimo\n",
    "max | Calcula el valor máximo\n",
    "count | Cuenta (generalmente usado sobre grupos o categorías)\n",
    "describe | Funciona también concatenado a `groupby`\n",
    "\n",
    "### Tu Turno\n",
    "1. Para ver más de una agregación, podemos usar una lista como argumento para `.agg()`.  Completa la última consulta añadiendo `median` y `std` a las funciones de agregación y el método `.filter()` a la consulta de modo que sólo se reporte el precio.  Recuerda que se filtra con una **lista**.  \n",
    "\n",
    "2. Otra opción en `.agg()` es definir tu propia función de agregación.  En este caso debemos pasar **el nombre de la función** directamente, **no en tipo** `str`.  Define tu propia función `iqr()` basada en `np.quantile` y añade esta función al resumen.  Asigna esta base al objeto `price_summary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nota\n",
    "\n",
    "Esta base de datos tiene un índice jerárquico para las columnas.  Las columnas ya no son `price_summary['mean']` ni `price_summary.loc[:, 'mean']`.  Ahora deberemos acceder a ellas con una `tuple` para el nombre de columna.  La primera entrada es el identificador exterior (`price`) y la segunda entrada es el identificador interior (`mean`, `median`, `std`, `iqr`).  Por ejemplo, podemos seleccionar\n",
    "```python\n",
    "price_summary.loc[: , ('price', ['mean'])]\n",
    "```\n",
    "Observe que `'mean'` aparece dentro de corchetes.  El seleccionar con una lista provoca que la respuesta sea del tipo `pandas.core.frame.DataFrame` y no del tipo `pandas.core.series.Series`.  En caso de brindar una lista más larga, la selección será de esas columnas.\n",
    "\n",
    "##### Práctica\n",
    "\n",
    "A modo de práctica:\n",
    "1. Genera una base de datos en la que se lea la media, desviación estándar y mediana para las variables `price` y `carat` (en ese orden) agrupados por la variable `cut`.\n",
    "2. Selecciona, de la base anterior, las columnas media y mediana para `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Usando los métodos de interacción de una tabla \n",
    "\n",
    "Estos cinco métodos son la base para responder preguntas concretas sobre la información presente en la base de datos. Para ejemplificar esto, usaremos la base de datos `msleep`, proveniende del paquete `ggplot2` de R y disponible en `https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/msleep.csv`.   Consulte la [descripción de esta base](https://ggplot2.tidyverse.org/reference/msleep.html).  \n",
    "\n",
    "Preguntas: \n",
    "1. Hay alguna diferencia en el tiempo total del sueño según el tipo de alimentación?\n",
    "2. Algún régimen alimenticio está asociado, en esta base, con cerebros más grandes (relativos al cuerpo)?\n",
    "3. Cuáles son los cinco animales que más tiempo duermen, qué porcentaje del día duermen, y qué dieta siguen?\n",
    "\n",
    "Respuestas posibles:\n",
    "```python\n",
    "# 1. -------\n",
    "(\n",
    " msleep\n",
    "    .filter(['sleep_total'])\n",
    "    .groupby('vore')\n",
    "    .agg(['mean', 'median', 'std', iqr])\n",
    ")\n",
    "\n",
    "\n",
    "# 1 extendida. -------\n",
    "\n",
    "def perc_over_10(x):\n",
    "    return np.mean(x >= 10)\n",
    "\n",
    "def perc_over_15(x):\n",
    "    return np.mean(x >= 15)\n",
    "\n",
    "(\n",
    "msleep\n",
    "    .filter(['vore', 'sleep_total'])\n",
    "    .groupby('vore')\n",
    "    .agg(['mean', 'median', iqr, perc_over_10, perc_over_15])\n",
    ")\n",
    "\n",
    "\n",
    "# 2. -------\n",
    "brainwt_data = (msleep\n",
    "    .filter(['vore', 'brainwt', 'bodywt'])\n",
    "    .assign(percentage_brainwt = lambda x: 100 * x.brainwt / x.bodywt)\n",
    "    .groupby('vore')\n",
    "    .agg(['mean', 'median', 'std', iqr, 'count']))\n",
    "\n",
    "brainwt_data.loc[:, ['percentage_brainwt']]\n",
    "\n",
    "\n",
    "# 3. ------\n",
    "\n",
    "(msleep\n",
    " .filter(['name', 'sleep_total','vore'])\n",
    " .assign(sleep_relative_day = lambda x: 100 * x.sleep_total / 24)\n",
    " .sort_values(by = 'sleep_total', ascending = False)\n",
    " .iloc[0:5, ]\n",
    ")\n",
    "\n",
    "```\n",
    "En la siguiente celda tienes el código para cargar la base de datos.  Utiliza las siguientes celdas para probar estas consultas. \n",
    "\n",
    "### Tu turno\n",
    "Trabajemos en grupo... Cada grupo deberá plantear 5 preguntas a su base de datos y responderlas con las 6 operaciones básicas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/msleep.csv'\n",
    "msleep = pd.read_csv(url, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega aquí las consultas que quieras ejeutar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping your data...otras formas de visualización y comunicación\n",
    "\n",
    "### 1. Pivotar\n",
    "Pandas ofrece distintos métodos para cambiar la forma de nuestros datos.  Exploremos primero con _pivotar_ tablas **sin agregar valores** sino únicamente cambiando de forma.\n",
    "```python\n",
    "df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two','two'],\n",
    "                   'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'baz': [1, 2, 3, 4, 5, 6],\n",
    "                   'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
    "\n",
    "df\n",
    "df.pivot(index = 'foo', columns = 'bar', values = 'baz')\n",
    "df.pivot(index = 'foo', columns = 'bar', values = ['baz', 'zoo'])\n",
    "df.pivot(index = 'foo', columns = 'bar')\n",
    "```\n",
    "El método no permite repeticiones y devolverá un `ValueError` si los encuentra como en\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\", \"bar\", \"bar\", \"bar\", \"bar\"],\n",
    "                        \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\", \"one\", \"one\", \"two\", \"two\"],\n",
    "                        \"C\": [\"small\", \"large\", \"large\", \"small\", \"small\", \"large\", \"small\", \"small\",\"large\"],\n",
    "                        \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
    "                        \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
    "df.pivot(index = 'A', columns = 'B', values = 'C')\n",
    "```\n",
    "\n",
    "Para casos como este, tenemos el método `.pivot_table()` que además de los argumentos `index`, `columns`, y `values`, utiliza el argumento `aggfunc`, la función para agregar los casos repetidos. Su valor por defecto es `numpy.mean`. Puede utilizarse una lista de funciones y el resultado será una tabla indexada jerarquicamente. \n",
    "\n",
    "```python\n",
    "df.pivot_table(index = 'A', columns = 'B', values = 'C', aggfunc = 'count')\n",
    "df.pivot_table(index = 'A', columns = 'B', values = 'D', aggfunc = 'sum')\n",
    "df.pivot_table(index = 'A', columns = 'B', values = 'D', aggfunc = ['mean', 'std'])\n",
    "df.pivot_table(index = 'A', columns = 'B', values = ['D', 'E'], aggfunc = ['mean', 'std'])\n",
    "df.pivot_table(index = 'A', columns = 'B', values = ['D', 'E'], aggfunc = ['mean', 'std'], margins = True)\n",
    "df.pivot_table(index = 'A', columns = 'B', aggfunc = ['mean', 'std'])  # Falta algo?\n",
    "df.pivot_table(index = 'A', columns = 'B', values = 'C', aggfunc = ['mean', 'std'])  # DataError\n",
    "\n",
    "df.pivot_table(index = ['A', 'B'], columns = 'C', values = 'D')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bar</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bar  A  B  C\n",
       "foo         \n",
       "one  1  2  3\n",
       "two  4  5  6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two','two'],\n",
    "                   'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'baz': [1, 2, 3, 4, 5, 6],\n",
    "                   'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
    "df.pivot(index = 'foo', columns = 'bar', values = 'baz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lo contrario...expandiendo nuestra base\n",
    "\n",
    "Pivotar la tabla produce una compresión de los datos. La operación contraria, expandir la base para ver todos sus registros, se puede llevar a cabo con el método `.melt()`.  Es un método útil cuando los nombres de columna son valores de una variable; esto es, cuando la tabla está pivotada.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-02 10:41:48.285833</th>\n",
       "      <td>1.012401</td>\n",
       "      <td>-0.525320</td>\n",
       "      <td>-2.206493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-02 15:41:48.285833</th>\n",
       "      <td>-0.196708</td>\n",
       "      <td>1.994933</td>\n",
       "      <td>-0.020539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-02 20:41:48.285833</th>\n",
       "      <td>-0.815031</td>\n",
       "      <td>-0.979125</td>\n",
       "      <td>3.615174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-03 01:41:48.285833</th>\n",
       "      <td>-1.620917</td>\n",
       "      <td>0.333095</td>\n",
       "      <td>9.185839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-03 06:41:48.285833</th>\n",
       "      <td>-0.003679</td>\n",
       "      <td>1.901970</td>\n",
       "      <td>1.223905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   X         Y         Z\n",
       "2020-09-02 10:41:48.285833  1.012401 -0.525320 -2.206493\n",
       "2020-09-02 15:41:48.285833 -0.196708  1.994933 -0.020539\n",
       "2020-09-02 20:41:48.285833 -0.815031 -0.979125  3.615174\n",
       "2020-09-03 01:41:48.285833 -1.620917  0.333095  9.185839\n",
       "2020-09-03 06:41:48.285833 -0.003679  1.901970  1.223905"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "stocks = pd.DataFrame({'X':np.random.normal(size = 10), 'Y': np.random.normal(scale = 2, size = 10),\n",
    "                       'Z':np.random.normal(size = 10, scale = 4)})\n",
    "stocks.index = pd.date_range(datetime.today(), periods = 10, freq = '5H')\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `.melt()` utiliza los siguientes argumentos:\n",
    "\n",
    "Argumento |  Uso\n",
    "---| --- \n",
    "id_vars |  Son las columnas de la base que no están pivotadas, aquéllas que son valores observados en sí\n",
    "value_vars | Refiere a las columnas de la base que contienen variables \n",
    "value_name | Tras el reacomodo, cómo se llama la variable que está registrada en los valores de las columnas pivotadas (qué representa?)\n",
    "var_name | Nombre de la variable que está registrada en las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>Retorno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X</td>\n",
       "      <td>1.012401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X</td>\n",
       "      <td>-0.196708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X</td>\n",
       "      <td>-0.815031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X</td>\n",
       "      <td>-1.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X</td>\n",
       "      <td>-0.003679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X</td>\n",
       "      <td>1.049084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X</td>\n",
       "      <td>0.851669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X</td>\n",
       "      <td>0.895696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X</td>\n",
       "      <td>0.801915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X</td>\n",
       "      <td>0.837260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Y</td>\n",
       "      <td>-0.525320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Y</td>\n",
       "      <td>1.994933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Y</td>\n",
       "      <td>-0.979125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.333095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Y</td>\n",
       "      <td>1.901970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Y</td>\n",
       "      <td>1.055689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Y</td>\n",
       "      <td>-1.634314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Y</td>\n",
       "      <td>-0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Y</td>\n",
       "      <td>-1.479378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.060275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Z</td>\n",
       "      <td>-2.206493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Z</td>\n",
       "      <td>-0.020539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Z</td>\n",
       "      <td>3.615174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Z</td>\n",
       "      <td>9.185839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Z</td>\n",
       "      <td>1.223905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Z</td>\n",
       "      <td>-3.534785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Z</td>\n",
       "      <td>2.727827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Z</td>\n",
       "      <td>0.432464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Z</td>\n",
       "      <td>-1.775279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Z</td>\n",
       "      <td>4.674348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stock   Retorno\n",
       "0      X  1.012401\n",
       "1      X -0.196708\n",
       "2      X -0.815031\n",
       "3      X -1.620917\n",
       "4      X -0.003679\n",
       "5      X  1.049084\n",
       "6      X  0.851669\n",
       "7      X  0.895696\n",
       "8      X  0.801915\n",
       "9      X  0.837260\n",
       "10     Y -0.525320\n",
       "11     Y  1.994933\n",
       "12     Y -0.979125\n",
       "13     Y  0.333095\n",
       "14     Y  1.901970\n",
       "15     Y  1.055689\n",
       "16     Y -1.634314\n",
       "17     Y -0.934165\n",
       "18     Y -1.479378\n",
       "19     Y  0.060275\n",
       "20     Z -2.206493\n",
       "21     Z -0.020539\n",
       "22     Z  3.615174\n",
       "23     Z  9.185839\n",
       "24     Z  1.223905\n",
       "25     Z -3.534785\n",
       "26     Z  2.727827\n",
       "27     Z  0.432464\n",
       "28     Z -1.775279\n",
       "29     Z  4.674348"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.melt(value_vars = ['X', 'Y', 'Z'], var_name = 'Stock', value_name = 'Retorno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tu turno: Reorganizando un juego de datos más grande...\n",
    "El Secretariado Ejecutivo del Sistema Nacional de Seguridad publica los datos de la incidencia delictiva del fuero común por estado. Para leerlos, hacemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "incidencia_fc = pd.read_csv('../Datos/IDEFC_NM_may2020.csv', encoding = 'iso-8859-1', thousands = ',')\n",
    "incidencia_fc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifica cuáles variables necesitamos reestructurar en el método melt y arregla la base de datos para que esté en un estado *tidy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiplomadoEnv",
   "language": "python",
   "name": "diplomadoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
